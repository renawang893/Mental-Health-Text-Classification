{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4672e64a",
   "metadata": {},
   "source": [
    "# Detecting Mental Health Distress in Online Text\n",
    "\n",
    "This notebook implements our course project: a text classifier that detects\n",
    "suicide and depression related posts. We use:\n",
    "1. A traditional ML baseline (TF-IDF + logistic regression).\n",
    "2. A transformer-based model (DistilBERT) fine-tuned on the Kaggle dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ede615",
   "metadata": {},
   "source": [
    "## 1. Data loading & preprocessing\n",
    "We load the Kaggle *Suicide and Depression Detection* dataset, inspect the columns,\n",
    "clean the text (lowercasing, removing URLs and mentions), and map string labels\n",
    "to integer IDs for modeling.\n",
    "\n",
    "*Slide: `nnintro-prompt` (motivation and NLP pipeline).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a7e856",
   "metadata": {},
   "source": [
    "### 1.1 Imports, device, and random seed\n",
    "\n",
    "We import the required libraries (PyTorch, pandas, scikit-learn, etc.), set\n",
    "the computation device (CPU/GPU), and fix random seeds for reproducibility.\n",
    "(Slide: `nnintro-prompt`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e08f6b-bc8a-4ba7-906b-67bc0f59eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3dc8f",
   "metadata": {},
   "source": [
    "### 1.2 Device and random seed setup\n",
    "\n",
    "We enable tqdm support, choose whether to use GPU or CPU, and set a fixed random\n",
    "seed for reproducibility. This makes our experiments easier to rerun and compare.\n",
    "(Slide: `nnintro-prompt`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9754c026-98e5-4279-91b8-f70834caa03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# # set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8989f",
   "metadata": {},
   "source": [
    "### 1.3 Load the dataset and preview rows\n",
    "\n",
    "We load the Kaggle *Suicide and Depression Detection* CSV file from disk and\n",
    "show the first few rows to understand the structure of the data.\n",
    "(Slide: `nnintro-prompt`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccc642f-af65-47b8-bd99-594347ea3d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does life actually work for most / non-depress...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I found my friend's bodyIt was almost nine yea...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Am I weird I don't get affected by compliments...</td>\n",
       "      <td>teenagers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
       "      <td>teenagers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         class\n",
       "0  Does life actually work for most / non-depress...    depression\n",
       "1  I found my friend's bodyIt was almost nine yea...    depression\n",
       "2  Ex Wife Threatening SuicideRecently I left my ...  SuicideWatch\n",
       "3  Am I weird I don't get affected by compliments...     teenagers\n",
       "4  Finally 2020 is almost over... So I can never ...     teenagers"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/SuicideAndDepression_Detection.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61280499",
   "metadata": {},
   "source": [
    "### 1.4 Check label distribution\n",
    "\n",
    "We compute the value counts of the `class` column to see how many examples we\n",
    "have for each label and whether the dataset is imbalanced.\n",
    "(Slides: `nnintro-prompt`, `nnintro-ch8-dist`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822168c1-152f-4e26-a754-8e204e570186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\26653\\AppData\\Local\\Temp\\ipykernel_28560\\788067207.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  pd.value_counts(df['class'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "SuicideWatch    116037\n",
       "teenagers       116037\n",
       "depression      116036\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04ff1b4-e033-4aae-8edd-2673ee1a3a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does life actually work for most / non-depressed people?It doesn't seem possible to me that everyone isn't miserable. What do you think? My boyfriend told me the other week that in reality we are the minority. Most people are fine, if not happy. Oddball.\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c9a14",
   "metadata": {},
   "source": [
    "### 1.6 Basic text normalization\n",
    "\n",
    "We normalize the text by lowercasing, removing backslashes, and slightly\n",
    "adjusting punctuation patterns. This is a simple cleanup step before modeling.\n",
    "(Slide: `nnintro-prompt` – basic NLP preprocessing.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc69c7e-02b1-4ffa-a5cd-069bb0fe97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('\\\\', '', regex=False)\n",
    "df['text'] = df['text'].str.replace(r'([?.!])([A-Z])', r'\\1 \\2', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f27d0",
   "metadata": {},
   "source": [
    "### 1.7 Inspect the example after cleaning\n",
    "\n",
    "We print the same example again after normalization to verify that the cleaning\n",
    "step worked as expected.\n",
    "(Slide: `nnintro-prompt`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707fffd3-9b19-415d-8b37-a16d821e74d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does life actually work for most / non-depressed people?it doesn't seem possible to me that everyone isn't miserable. what do you think? my boyfriend told me the other week that in reality we are the minority. most people are fine, if not happy. oddball.\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a7c16",
   "metadata": {},
   "source": [
    "### 1.8 Map string labels to integer IDs\n",
    "\n",
    "We map each label string to an integer ID (`teenagers` → 0, `depression` → 1,\n",
    "`SuicideWatch` → 2), which is the format required by our models.\n",
    "(Slide: `nnintro-prompt` – basic ML setup.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec97c6c-3a69-472c-9e6c-dbbbcea6c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"teenagers\": 0,\n",
    "    \"depression\": 1,\n",
    "    \"SuicideWatch\": 2\n",
    "}\n",
    "df['class'] = df['class'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c5982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution after mapping (full dataset):\n",
      "class\n",
      "2.0    116037\n",
      "0.0    116037\n",
      "1.0    116036\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Text length statistics:\n",
      "count    348123.000000\n",
      "mean        897.267836\n",
      "std        1322.454725\n",
      "min           3.000000\n",
      "25%         183.000000\n",
      "50%         472.000000\n",
      "75%        1102.000000\n",
      "max       40297.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Label distribution after mapping (full dataset):\")\n",
    "print(df[\"class\"].value_counts())\n",
    "\n",
    "df[\"text_len\"] = df[\"text\"].str.len()\n",
    "print(\"\\nText length statistics:\")\n",
    "print(df[\"text_len\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe5114",
   "metadata": {},
   "source": [
    "### 1.9 Check for missing labels\n",
    "\n",
    "We count how many rows have missing (`NaN`) values in the `class` column to\n",
    "avoid training on incomplete labels.\n",
    "(Slide: `nnintro-ch8-dist` – data quality and evaluation.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8d205b-b7b1-4aba-aa19-9bec6a50f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN rows in 'class': 14\n"
     ]
    }
   ],
   "source": [
    "nan_count = df['class'].isna().sum()\n",
    "print(f\"Number of NaN rows in 'class': {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92521cf",
   "metadata": {},
   "source": [
    "### 1.10 Inspect rows with missing labels\n",
    "\n",
    "We inspect the rows with missing labels to see what kind of data is being\n",
    "removed and confirm that this cleanup step is reasonable.\n",
    "(Slide: `nnintro-ch8-dist`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d750d7-1222-4215-852c-b741c829b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>i feel like im in a nightmare.something happen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>it's like i'm living in a nightmare and everyt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>(view post history for more info on my dad)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41048</th>\n",
       "      <td>a doodle of my struggle with depressionhttp://...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47570</th>\n",
       "      <td>thinking of putting this as my profile picture...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61160</th>\n",
       "      <td>if i told you i want to move on with my life a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141715</th>\n",
       "      <td>i think i might need someone to talk me down f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>802.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141716</th>\n",
       "      <td>i've known that i'll never get any love outsid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156657</th>\n",
       "      <td>a clip that describes how i feel when i'm tryi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156658</th>\n",
       "      <td>depression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185321</th>\n",
       "      <td>telling your so that you have depressionmy so ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185322</th>\n",
       "      <td>could you guys tell me about your own experien...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191282</th>\n",
       "      <td>i want to run away and start overi can't take ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265687</th>\n",
       "      <td>i had to write my own eulogy for my english cl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  class  text_len\n",
       "11557   i feel like im in a nightmare.something happen...    NaN     520.0\n",
       "11558   it's like i'm living in a nightmare and everyt...    NaN      67.0\n",
       "11559         (view post history for more info on my dad)    NaN      43.0\n",
       "41048   a doodle of my struggle with depressionhttp://...    NaN      63.0\n",
       "47570   thinking of putting this as my profile picture...    NaN     107.0\n",
       "61160   if i told you i want to move on with my life a...    NaN     223.0\n",
       "141715  i think i might need someone to talk me down f...    NaN     802.0\n",
       "141716  i've known that i'll never get any love outsid...    NaN      82.0\n",
       "156657  a clip that describes how i feel when i'm tryi...    NaN     119.0\n",
       "156658                                         depression    NaN      10.0\n",
       "185321  telling your so that you have depressionmy so ...    NaN     168.0\n",
       "185322  could you guys tell me about your own experien...    NaN      97.0\n",
       "191282  i want to run away and start overi can't take ...    NaN     157.0\n",
       "265687  i had to write my own eulogy for my english cl...    NaN     117.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12a21a",
   "metadata": {},
   "source": [
    "### 1.11 Drop rows with missing labels\n",
    "\n",
    "We drop all rows whose `class` label is missing and reset the index. This keeps\n",
    "only fully labeled examples for training and evaluation.\n",
    "(Slide: `nnintro-ch8-dist`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d33d6cff-3832-41d7-9e27-6e047a037d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['class']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5975b",
   "metadata": {},
   "source": [
    "### 1.12 Train/dev split\n",
    "\n",
    "We split the cleaned dataset into a training set and a development (validation)\n",
    "set, stratifying by label so that the class distribution is similar in both\n",
    "splits.\n",
    "(Slide: `nnintro-ch8-dist` – train/dev splits.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed06b06-6800-42e4-b82e-c6ec006a3ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 278,488, Dev rows: 69,622\n"
     ]
    }
   ],
   "source": [
    "train_df, dev_df = train_test_split(df, train_size=0.8, random_state=seed, stratify=df['class'])\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "dev_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Train rows: {len(train_df):,}, Dev rows: {len(dev_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02a6f3",
   "metadata": {},
   "source": [
    "### 1.13 Ensure text column is string\n",
    "\n",
    "We ensure the `text` column is stored as strings in both the training and\n",
    "development dataframes, which avoids type issues in later preprocessing.\n",
    "(Slide: `nnintro-prompt`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bcd5b3-8729-47b7-a79c-964f0172662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].astype(str)\n",
    "dev_df['text'] = dev_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb451d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbe6b7",
   "metadata": {},
   "source": [
    "## 2. Baseline: TF-IDF + Logistic Regression\n",
    "\n",
    "We build a baseline classifier using TF-IDF features and multinomial logistic\n",
    "regression. TF-IDF turns each post into a sparse feature vector, and logistic\n",
    "regression learns a linear decision boundary with softmax and cross-entropy.\n",
    "\n",
    "*Slides: `nnintro-ch3-lr`, `nnintro-ch5-ffnn`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a97de",
   "metadata": {},
   "source": [
    "### 2.1 Prepare texts and labels\n",
    "\n",
    "We extract the raw texts and integer labels from the train and dev splits to\n",
    "use as input and targets for the baseline classifier.\n",
    "(Slides: `nnintro-ch3-lr`, `nnintro-ch5-ffnn`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e7a207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_texts = train_df[\"text\"].astype(str)\n",
    "dev_texts   = dev_df[\"text\"].astype(str)\n",
    "train_labels = train_df[\"class\"].values\n",
    "dev_labels   = dev_df[\"class\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab0f13",
   "metadata": {},
   "source": [
    "### 2.2 Build TF-IDF features\n",
    "\n",
    "We convert each document into a sparse TF-IDF vector over unigrams and\n",
    "bigrams. These vectors are the input features to our linear classifier.\n",
    "(Slides: `nnintro-ch3-lr`, `nnintro-ch5-ffnn`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e55861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (278488, 20000)\n",
      "TF-IDF dev   shape: (69622, 20000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,      # vocab size\n",
    "    ngram_range=(1, 2),      # unigram + bigram\n",
    "    min_df=5                 # drop very rare terms\n",
    ")\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_dev   = vectorizer.transform(dev_texts)\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_train.shape)\n",
    "print(\"TF-IDF dev   shape:\", X_dev.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0881a17",
   "metadata": {},
   "source": [
    "### 2.3 Train multinomial logistic regression\n",
    "\n",
    "We train a multinomial logistic regression model on the TF-IDF features, which\n",
    "is equivalent to a one-layer neural network with a softmax output.\n",
    "(Slides: `nnintro-ch3-lr`, `nnintro-ch5-ffnn`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "312c5a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_clf.fit(X_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24b4cc",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate the baseline on the dev set\n",
    "\n",
    "We evaluate the TF-IDF + logistic regression baseline on the dev set using the\n",
    "classification report (precision, recall, and F1 for each class).\n",
    "(Slides: `nnintro-ch3-lr`, `nnintro-ch8-dist`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd876807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline: Logistic Regression on TF-IDF features ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   teenagers       0.89      0.93      0.91     23207\n",
      "  depression       0.77      0.75      0.76     23207\n",
      "SuicideWatch       0.78      0.76      0.77     23208\n",
      "\n",
      "    accuracy                           0.82     69622\n",
      "   macro avg       0.81      0.82      0.81     69622\n",
      "weighted avg       0.81      0.82      0.81     69622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_pred = lr_clf.predict(X_dev)\n",
    "\n",
    "id_to_label = {v: k for k, v in label_mapping.items()}\n",
    "target_names = [id_to_label[i] for i in sorted(id_to_label.keys())]\n",
    "\n",
    "print(\"\\n=== Baseline: Logistic Regression on TF-IDF features ===\")\n",
    "print(classification_report(dev_labels, dev_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265938a",
   "metadata": {},
   "source": [
    "### 2.5 Free memory used by the baseline\n",
    "\n",
    "After running the TF-IDF + logistic regression baseline, we delete the large\n",
    "TF-IDF matrices and related variables to free RAM before loading the transformer\n",
    "model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edacaee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free large baseline objects to save RAM\n",
    "del X_train, X_dev\n",
    "del train_texts, dev_texts\n",
    "del train_labels, dev_labels\n",
    "del lr_clf, vectorizer\n",
    "\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb7d57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff1986",
   "metadata": {},
   "source": [
    "## 3. Transformer-based model (DistilBERT fine-tuning)\n",
    "\n",
    "We fine-tune a pre-trained DistilBERT model for three-way text classification.\n",
    "Posts are tokenized into subwords, encoded by the transformer, and the [CLS]\n",
    "representation is passed to a linear classification head.\n",
    "\n",
    "*Slide: `nnintro-ch12-transformer`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97005f",
   "metadata": {},
   "source": [
    "### 3.1 Tokenization with DistilBERT\n",
    "\n",
    "We load the DistilBERT tokenizer and tokenize all train and dev texts into\n",
    "subword IDs with padding and truncation. This produces the input tensors that\n",
    "will be fed into the transformer model.\n",
    "(Slide: `nnintro-ch12-transformer`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ded9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded. max_length = 128\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# shorter sequence length to save memory\n",
    "max_length = 128\n",
    "\n",
    "print(\"Tokenizer loaded. max_length =\", max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b4451",
   "metadata": {},
   "source": [
    "### 3.2 Torch Dataset wrapper\n",
    "\n",
    "We define a `TransformerDataset` class that wraps the tokenized encodings and\n",
    "labels into a PyTorch `Dataset`, so that we can iterate over examples with a\n",
    "DataLoader.\n",
    "(Slides: `nnintro-ch5-ffnn`, `nnintro-ch12-transformer`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "360bb709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example item from train_dataset:\n",
      "input_ids shape: torch.Size([128]), dtype: torch.int64\n",
      "attention_mask shape: torch.Size([128]), dtype: torch.int64\n",
      "label: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class OnTheFlyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Tokenize each example on the fly inside __getitem__.\n",
    "    This avoids storing all tokenized encodings in memory at once\n",
    "    and avoids a long blocking pre-processing step.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.texts = df[\"text\"].tolist()\n",
    "        self.labels = df[\"class\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text  = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = OnTheFlyDataset(train_df, tokenizer, max_length=max_length)\n",
    "dev_dataset   = OnTheFlyDataset(dev_df, tokenizer, max_length=max_length)\n",
    "\n",
    "print(\"Example item from train_dataset:\")\n",
    "sample = train_dataset[0]\n",
    "for key in sample:\n",
    "    if key != \"labels\":\n",
    "        print(f\"{key} shape: {sample[key].shape}, dtype: {sample[key].dtype}\")\n",
    "print(\"label:\", sample[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c1380",
   "metadata": {},
   "source": [
    "### 3.3 DataLoaders for training and dev\n",
    "\n",
    "We create PyTorch `DataLoader` objects for the training and development sets,\n",
    "which handle batching and shuffling of examples during training.\n",
    "(Slide: `nnintro-ch5-ffnn` – minibatch training.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a73438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train batches: 2176\n",
      "# dev   batches: 544\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0  \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"# train batches: {len(train_loader)}\")\n",
    "print(f\"# dev   batches: {len(dev_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbb0dc",
   "metadata": {},
   "source": [
    "### 3.4 Model and optimizer setup\n",
    "\n",
    "We load a pre-trained `DistilBertForSequenceClassification` model, move it to\n",
    "the chosen device, and set up the optimizer and learning-rate scheduler for\n",
    "fine-tuning.\n",
    "(Slide: `nnintro-ch12-transformer`.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bfb9800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "num_labels = 3  # teenagers / depression / SuicideWatch\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 3  # you can change this\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(\"Model loaded on:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4ffb3",
   "metadata": {},
   "source": [
    "### 3.5 Training loop and dev metrics\n",
    "\n",
    "We fine-tune the DistilBERT model for several epochs. After each epoch we\n",
    "evaluate on the dev set and report accuracy, macro precision, macro recall,\n",
    "and macro F1.\n",
    "(Slides: `nnintro-ch12-transformer`, `nnintro-ch8-dist`.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c433f",
   "metadata": {},
   "source": [
    "add ipywidgets if your system not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12d71298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ipywidgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15b063c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "use_amp = (device.type == \"cuda\")   \n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afdfc2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f06c68561fe47ea9419667e8e985840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 - train:   0%|          | 0/2176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b684e7bf0e4bbe812ccea51b57d5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 - dev:   0%|          | 0/544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "  train loss        : 0.3910\n",
      "  dev accuracy      : 0.8560\n",
      "  dev macro-prec.   : 0.8558\n",
      "  dev macro-recall  : 0.8560\n",
      "  dev macro-F1      : 0.8559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c842f9adda745e594d4d5734204c183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 - train:   0%|          | 0/2176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23621afb634644e997a17d21219133b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 - dev:   0%|          | 0/544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "  train loss        : 0.3133\n",
      "  dev accuracy      : 0.8599\n",
      "  dev macro-prec.   : 0.8603\n",
      "  dev macro-recall  : 0.8599\n",
      "  dev macro-F1      : 0.8601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5250431a26546498729193d3752273a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 - train:   0%|          | 0/2176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719467096492460eaf0a42f0c0495240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 - dev:   0%|          | 0/544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3\n",
      "  train loss        : 0.2795\n",
      "  dev accuracy      : 0.8604\n",
      "  dev macro-prec.   : 0.8604\n",
      "  dev macro-recall  : 0.8604\n",
      "  dev macro-F1      : 0.8604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - train\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "\n",
    "        with torch.autocast(\n",
    "            device_type=device.type,   \n",
    "            dtype=torch.float16,       \n",
    "            enabled=use_amp           \n",
    "        ):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # ---- eval on dev ----\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dev_loader, desc=f\"Epoch {epoch+1}/{epochs} - dev\"):\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "\n",
    "            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    print(f\"  train loss        : {avg_train_loss:.4f}\")\n",
    "    print(f\"  dev accuracy      : {acc:.4f}\")\n",
    "    print(f\"  dev macro-prec.   : {prec:.4f}\")\n",
    "    print(f\"  dev macro-recall  : {rec:.4f}\")\n",
    "    print(f\"  dev macro-F1      : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2e929",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386ed38",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Error Analysis\n",
    "\n",
    "We evaluate both models on a held-out development set using accuracy, precision,\n",
    "recall, and macro F1. We also inspect misclassified examples to understand\n",
    "typical errors and limitations.\n",
    "\n",
    "*Slide: `nnintro-ch8-dist` (distributions and evaluation).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872fcbd",
   "metadata": {},
   "source": [
    "### 4.1 Collect misclassified examples\n",
    "\n",
    "Using the fine-tuned transformer and the dev DataLoader, we collect predictions,\n",
    "compare them with the gold labels, and build a DataFrame of misclassified\n",
    "examples for qualitative error analysis.\n",
    "(Slide: `nnintro-ch8-dist` – evaluation and model analysis.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "221b3cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c2615c59a04ef2a51f017d1a516931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting predictions for error analysis:   0%|          | 0/544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# misclassified examples: 9722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gold</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the only psychiatrist i could get in contact w...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29 m just not good enough. i ' m off my antide...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i ' m ready! haha yay!... please be happy. i h...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>decided to quit my major, buying gun sooni pos...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>i don ' t know anymoreman, i am just really mi...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>i am cripplingly addicted to custard edit : r ...</td>\n",
       "      <td>teenagers</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>so depressed right nowit always happens i do s...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>just 2 hours left : ) my parents are going to ...</td>\n",
       "      <td>depression</td>\n",
       "      <td>SuicideWatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>everything is falling apart i originally poste...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>teenagers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>i ' m tempted to kill my self. i keep telling ...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text          gold  \\\n",
       "2   the only psychiatrist i could get in contact w...  SuicideWatch   \n",
       "5   29 m just not good enough. i ' m off my antide...  SuicideWatch   \n",
       "23  i ' m ready! haha yay!... please be happy. i h...  SuicideWatch   \n",
       "30  decided to quit my major, buying gun sooni pos...  SuicideWatch   \n",
       "31  i don ' t know anymoreman, i am just really mi...  SuicideWatch   \n",
       "35  i am cripplingly addicted to custard edit : r ...     teenagers   \n",
       "51  so depressed right nowit always happens i do s...  SuicideWatch   \n",
       "52  just 2 hours left : ) my parents are going to ...    depression   \n",
       "55  everything is falling apart i originally poste...  SuicideWatch   \n",
       "79  i ' m tempted to kill my self. i keep telling ...  SuicideWatch   \n",
       "\n",
       "            pred  \n",
       "2     depression  \n",
       "5     depression  \n",
       "23    depression  \n",
       "30    depression  \n",
       "31    depression  \n",
       "35    depression  \n",
       "51    depression  \n",
       "52  SuicideWatch  \n",
       "55     teenagers  \n",
       "79    depression  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build id_to_label mapping (inverse of label_mapping)\n",
    "id_to_label = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels, all_texts = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_loader, desc=\"Collecting predictions for error analysis\"):\n",
    "        labels = batch[\"labels\"].numpy()\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        \n",
    "        batch_device = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch_device)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_labels.extend(labels)\n",
    "        all_preds.extend(preds)\n",
    "        \n",
    "        texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "        all_texts.extend(texts)\n",
    "\n",
    "error_df = pd.DataFrame({\n",
    "    \"text\": all_texts,\n",
    "    \"gold\": [id_to_label[int(y)] for y in all_labels],\n",
    "    \"pred\": [id_to_label[int(y)] for y in all_preds]\n",
    "})\n",
    "\n",
    "errors = error_df[error_df[\"gold\"] != error_df[\"pred\"]]\n",
    "print(f\"# misclassified examples: {len(errors)}\")\n",
    "\n",
    "# show a few misclassified examples\n",
    "errors.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47eeed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f98ad",
   "metadata": {},
   "source": [
    "## 5. Save model & conclusions\n",
    "\n",
    "We save the fine-tuned model and tokenizer for future use and summarize the main\n",
    "results: comparison between the baseline and the transformer model, and ideas\n",
    "for potential improvements.\n",
    "\n",
    "*Slide: `nnintro-prompt` (research mindset and applications).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1acc8176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to: saved_distilbert_model\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"saved_distilbert_model\"\n",
    "\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4d7d0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b3825",
   "metadata": {},
   "source": [
    "## References to course slides\n",
    "\n",
    "- `nnintro-prompt`: Motivation, NLP applications, research mindset.\n",
    "- `nnintro-ch3-lr`: Logistic regression and softmax classification.\n",
    "- `nnintro-ch5-ffnn`: Feed-forward neural networks.\n",
    "- `nnintro-ch8-dist`: Data distributions and evaluation metrics.\n",
    "- `nnintro-ch12-transformer`: Transformer architecture and self-attention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
